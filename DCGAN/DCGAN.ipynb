{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwGzEWGw_6MH"
   },
   "source": [
    "# [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "### Alec Radford, Luke Metz & Soumith Chintala\n",
    "\n",
    "Like every GAN consist of a Generator and a Discriminator that fight in a min-max game.\n",
    "\n",
    "The architecture of the Generator is as follows:\n",
    "\n",
    "<img src=\"images/DCGAN-Generator.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urWqMYrT_6MO"
   },
   "source": [
    "## Set Up the DCGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1581357440550,
     "user": {
      "displayName": "Florian C. F. Schulz",
      "photoUrl": "",
      "userId": "08634931705470539405"
     },
     "user_tz": -60
    },
    "id": "l6TOtkqe_6MU",
    "outputId": "4d683c6f-bf4c-4c21-c74a-eed0a242dc37"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Check for CUDA device\n",
    "device_txt = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_txt)\n",
    "# Print Device Type\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "\n",
    "######################\n",
    "# Define Training Details\n",
    "epochs     = 100\n",
    "batch_size = 128\n",
    "# Learning Rate (Adam) and betas\n",
    "lr    = 0.0002\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrnLRRv0_6Mt"
   },
   "source": [
    "### Googke Colab Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1-gRD1Q_6My"
   },
   "outputs": [],
   "source": [
    "!mkdir data saved_models\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1A_Lly2FzHiCpZXTLdWntZHNejojoW8fz' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1A_Lly2FzHiCpZXTLdWntZHNejojoW8fz\" -O data/celeba.tar && rm -rf /tmp/cookies.txt\n",
    "!tar xf data/celeba.tar -C data/ && rm data/celeba.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqBkXGFY_6NC"
   },
   "source": [
    "#### Construct Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzmiRLrh_6NK"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf):\n",
    "        super(Generator, self).__init__()\n",
    "        # Save Hypterparameters\n",
    "        self.nz  = nz\n",
    "        # 1st layer input: batch_size x 100 x 1 x 1 (for nz = 100)\n",
    "        self.deconv_1 = nn.ConvTranspose2d(in_channels=nz, out_channels=8*ngf, kernel_size=4, bias=False)\n",
    "        self.bn_1   = nn.BatchNorm2d(num_features=8*ngf)\n",
    "        # 2nd layer input: batch_size x 1024 x 4 x 4 (for ngf = 128)\n",
    "        self.deconv_2 = nn.ConvTranspose2d(in_channels=8*ngf, out_channels=4*ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_2   = nn.BatchNorm2d(num_features=4*ngf)\n",
    "        # 3rd layer input: batch_size x 512 x 8 x 8 (for ngf = 128)\n",
    "        self.deconv_3 = nn.ConvTranspose2d(in_channels=4*ngf, out_channels=2*ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_3   = nn.BatchNorm2d(num_features=2*ngf)\n",
    "        # 4th layer input: batch_size x 256 x 16 x 16 (for ngf = 128)\n",
    "        self.deconv_4 = nn.ConvTranspose2d(in_channels=2*ngf, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_4   = nn.BatchNorm2d(num_features=ngf)\n",
    "        # Final layer input: batch_size x 128 x 32 x 32 (for ngf = 128)\n",
    "        self.deconv_5 = nn.ConvTranspose2d(in_channels=ngf, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # Output size: batch_size x 3 x 64 x 64\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Forward 1st layer\n",
    "        input = F.relu(self.bn_1(self.deconv_1(input)), inplace=True)\n",
    "        # Forward 2nd layer\n",
    "        input = F.relu(self.bn_2(self.deconv_2(input)), inplace=True)\n",
    "        # Forward 3rd layer\n",
    "        input = F.relu(self.bn_3(self.deconv_3(input)), inplace=True)\n",
    "        # Forward 4th layer\n",
    "        input = F.relu(self.bn_4(self.deconv_4(input)), inplace=True)\n",
    "        # Final layer\n",
    "        return torch.tanh(self.deconv_5(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yh2qZOFj_6Nf"
   },
   "source": [
    "#### Construct Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lf1ta9F3_6Nm"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # 1st layer input: batch_size x 3 x 64 x 64\n",
    "        self.conv_1  = nn.Conv2d(in_channels=3, out_channels=ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # 2nd layer input: batch_size x 128 x 32 x 32 (for ndf = 128)\n",
    "        self.conv_2  = nn.Conv2d(in_channels=ndf, out_channels=2*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_2    = nn.BatchNorm2d(num_features=2*ndf)\n",
    "        # 3rd layer input: batch_size x 256 x 16 x 16 (for ndf = 128)\n",
    "        self.conv_3  = nn.Conv2d(in_channels=2*ndf, out_channels=4*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_3    = nn.BatchNorm2d(num_features=4*ndf)\n",
    "        # 4th layer input: batch_size x 512 x 8 x 8 (for ndf = 128)\n",
    "        self.conv_4  = nn.Conv2d(in_channels=4*ndf, out_channels=8*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_4    = nn.BatchNorm2d(num_features=8*ndf)\n",
    "        # Final layer input: batch_size x 1024 x 4 x 4 (for ndf = 128)\n",
    "        self.conv_5  = nn.Conv2d(in_channels=8*ndf, out_channels=1, kernel_size=4, bias=False)\n",
    "        # Output size: batch_size x 1 x 1 x 1\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Forward 1st layer\n",
    "        input = F.leaky_relu(self.conv_1(input), negative_slope=0.2, inplace=True)\n",
    "        # Forward 2nd layer\n",
    "        input = F.leaky_relu(self.bn_2(self.conv_2(input)), negative_slope=0.2, inplace=True)\n",
    "        # Forward 3rd layer\n",
    "        input = F.leaky_relu(self.bn_3(self.conv_3(input)), negative_slope=0.2, inplace=True)\n",
    "        # Forward 4th layer\n",
    "        input = F.leaky_relu(self.bn_4(self.conv_4(input)), negative_slope=0.2, inplace=True)\n",
    "        # Final layer\n",
    "        return torch.sigmoid(self.conv_5(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2S1Qjly_6OA"
   },
   "source": [
    "#### Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlTY-Qp4_6OD"
   },
   "outputs": [],
   "source": [
    "# custom weights initialization (page 3)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA7kY1Nl_6OO"
   },
   "source": [
    "#### Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hoLWh7Z_6OT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_dcgan(nz, ngf, ndf, device, lr=0.0002, betas=(0.5, 0.999)):\n",
    "    # Get models\n",
    "    model_G = Generator(nz=nz, ngf=ngf).to(device)\n",
    "    model_D = Discriminator(ndf=ndf).to(device)\n",
    "    \n",
    "    # Init weights\n",
    "    [m.apply(weights_init) for m in (model_G, model_D)]\n",
    "    # Set starting epoch to 0 as default\n",
    "    epoch_start    = 0\n",
    "    \n",
    "    # Check for pretrained Model\n",
    "    if os.path.isfile('./saved_models/DCGAN_saved_model.tar'):\n",
    "        pretrained = \"Users_answer\"\n",
    "        while pretrained not in [\"y\",\"n\"]:\n",
    "            pretrained = input(\"Pretrained Model available, use it? [y/n]:\")\n",
    "        # If User says \"y\", load weights\n",
    "        if pretrained==\"y\":\n",
    "            # Load data\n",
    "            saved_data = torch.load('./saved_models/DCGAN_saved_model.tar', map_location=device)\n",
    "            # Transmit data\n",
    "            model_G.load_state_dict(saved_data['G_state_dict'])\n",
    "            model_D.load_state_dict(saved_data['D_state_dict'])\n",
    "            epoch_start    = saved_data['current_epoch']\n",
    "            \n",
    "    # Define Adam optimizer\n",
    "    opt_G = optim.Adam(model_G.parameters(), lr=lr, betas=betas)\n",
    "    opt_D = optim.Adam(model_D.parameters(), lr=lr, betas=betas)\n",
    "    \n",
    "    return model_G, model_D, opt_G, opt_D, epoch_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0VZfO9n_6Oh"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LdTi06v_6Oj"
   },
   "outputs": [],
   "source": [
    "def fit_dcgan(epochs, model_G, model_D, loss_func, opt_G, opt_D, train_dl, device, \n",
    "              epoch_start=0, show_iter=None):\n",
    "    \n",
    "    # Check if start_epoch is greater than number of epochs, stop if the case\n",
    "    if epoch_start>epochs:\n",
    "        return\n",
    "    \n",
    "    # If not otherwise defined: show_iter = one epoch\n",
    "    if show_iter is None:\n",
    "      show_iter=len(train_dl)\n",
    "\n",
    "    # Take time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epoch_start, epochs):\n",
    "        for i, (x_real, _) in enumerate(train_dl):\n",
    "            # Get batch_size since batch_size is different for last observations\n",
    "            batch_size = x_real.size()[0]\n",
    "            \n",
    "            ### Discriminator Training ###\n",
    "            model_D.zero_grad()\n",
    "            # Real pictures\n",
    "            out_real = model_D(x_real.to(device)).view(-1)\n",
    "            lossD_real = loss_func(out_real, torch.ones(batch_size, device=device))\n",
    "            \n",
    "            # Fake pictures \n",
    "            ## Generate Noise\n",
    "            noise = torch.randn(batch_size, model_G.nz, 1, 1, device=device)\n",
    "            out_fake_D = model_D(model_G(noise).detach()).view(-1)\n",
    "            # Loss function with all zeros for being fake\n",
    "            lossD_fake = loss_func(out_fake_D, torch.zeros(batch_size, device=device))\n",
    "            lossD = lossD_real + lossD_fake\n",
    "            \n",
    "            lossD.backward()\n",
    "            opt_D.step()\n",
    "            \n",
    "            ### Generator Training ###\n",
    "            model_G.zero_grad()\n",
    "            out_fake_G = model_D(model_G(noise)).view(-1)\n",
    "            lossG = loss_func(out_fake_G, torch.ones(batch_size, device=device))\n",
    "            \n",
    "            lossG.backward()\n",
    "            opt_G.step()\n",
    "            \n",
    "            if (i+epoch*len(train_dl))%show_iter == 0:\n",
    "                # get time values\n",
    "                hours, rem = divmod(time.time()-start_time, 3600)\n",
    "                minutes, seconds = divmod(rem, 60)\n",
    "                print('({:0>2}:{:0>2}:{:0>2}) [{}/{}][{}/{}] -> {:.2f}%\\tLoss_D: {:.4f}, D(x): {:.4f}\\tLoss_G: {:.4f}, D(G(z)): {:.4f}'.format(\n",
    "                    int(hours),int(minutes), int(seconds), epoch, epochs, i, len(train_dl),\n",
    "                    100*(i+epoch*len(train_dl))/(epochs*len(train_dl)), lossD, out_real.mean(),\n",
    "                    lossG, out_fake_D.mean()))\n",
    "                \n",
    "            if (i+epoch*len(train_dl))%(5*show_iter) == 0:\n",
    "                # Plot some training images\n",
    "                fakes = model_G(torch.randn(16,model_G.nz,1,1,device=device)).detach().cpu()\n",
    "                plt.figure(figsize=(12,12))\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(\"Generated Images\")\n",
    "                plt.imshow(np.transpose(vutils.make_grid(fakes, padding=1, normalize=True),(1,2,0)))\n",
    "                plt.pause(0.001)\n",
    "                \n",
    "        ###############\n",
    "        # save current state, epoch and saved losses\n",
    "        torch.save({'G_state_dict': model_G.state_dict(),\n",
    "                    'D_state_dict': model_D.state_dict(),\n",
    "                    'current_epoch': epoch+1\n",
    "                   },'./saved_models/DCGAN_saved_model.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtqU4Y_q_6Os"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3112,
     "status": "ok",
     "timestamp": 1581357519595,
     "user": {
      "displayName": "Florian C. F. Schulz",
      "photoUrl": "",
      "userId": "08634931705470539405"
     },
     "user_tz": -60
    },
    "id": "areYhLoH_6Ov",
    "outputId": "265a9636-f95d-4bd7-c3ce-da23c985f09d"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Define Image size\n",
    "image_size = 64\n",
    "# Select dataset\n",
    "data_folder = './data/'\n",
    "\n",
    "train_ds = dset.ImageFolder(root = data_folder,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                # Transform data from [0,1] scale to [-1,1] scale\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ]))\n",
    "# Constuct dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "# Plot some training images\n",
    "real_examples = next(iter(train_dl))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_examples[0][:16], padding=1, normalize=True),(1,2,0)))\n",
    "plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "colab_type": "code",
    "id": "Z8pXVJLX_6O7",
    "outputId": "f4bd746a-1e25-40de-82c4-c2ccefbbc08b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_func = nn.BCELoss()\n",
    "# Get initialized models and optimizers\n",
    "model_G, model_D, opt_G, opt_D, epoch_start = get_dcgan(nz=100, ngf=64, ndf=64, device=device, lr=lr, betas=betas)\n",
    "# Fit DCGAN\n",
    "fit_dcgan(epochs, model_G, model_D, loss_func, opt_G, opt_D, train_dl, device, epoch_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_xpHlDY_6Pn"
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcvJ4GCX_6Pr"
   },
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "fakes = model_G(torch.randn(64,100,1,1,device=device)).detach().cpu()\n",
    "plt.figure(figsize=(13,13))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(fakes, padding=1, normalize=True),(1,2,0)))\n",
    "plt.pause(0.001)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
