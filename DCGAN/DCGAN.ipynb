{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "### Alec Radford, Luke Metz & Soumith Chintala\n",
    "\n",
    "Like every GAN consist of a Generator and a Discriminator that fight in a min-max game.\n",
    "\n",
    "The architecture of the Generator is as follows:\n",
    "\n",
    "<img src=\"images/DCGAN-Generator.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the DCGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Check for CUDA device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Googke Colab Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data saved_models\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\" -O data/celeba.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip -qq -o data/celeba.zip -d data/ && rm data/celeba.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf):\n",
    "        super(Generator, self).__init__()\n",
    "        # Save Hypterparameters\n",
    "        self.nz  = nz\n",
    "        # 1st layer input: batch_size x 100 x 1 x 1 (for nz = 100)\n",
    "        self.deconv_1 = nn.ConvTranspose2d(in_channels=nz, out_channels=8*ngf, kernel_size=4, bias=False)\n",
    "        self.bn_1   = nn.BatchNorm2d(num_features=8*ngf)\n",
    "        # 2nd layer input: batch_size x 1024 x 4 x 4 (for ngf = 128)\n",
    "        self.deconv_2 = nn.ConvTranspose2d(in_channels=8*ngf, out_channels=4*ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_2   = nn.BatchNorm2d(num_features=4*ngf)\n",
    "        # 3rd layer input: batch_size x 512 x 8 x 8 (for ngf = 128)\n",
    "        self.deconv_3 = nn.ConvTranspose2d(in_channels=4*ngf, out_channels=2*ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_3   = nn.BatchNorm2d(num_features=2*ngf)\n",
    "        # 4th layer input: batch_size x 256 x 16 x 16 (for ngf = 128)\n",
    "        self.deconv_4 = nn.ConvTranspose2d(in_channels=2*ngf, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_4   = nn.BatchNorm2d(num_features=ngf)\n",
    "        # Final layer input: batch_size x 128 x 32 x 32 (for ngf = 128)\n",
    "        self.deconv_5 = nn.ConvTranspose2d(in_channels=ngf, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # Output size: batch_size x 3 x 64 x 64\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Forward 1st layer\n",
    "        input = F.relu(self.bn_1(self.deconv_1(input)), inplace=True)\n",
    "        # Forward 2nd layer\n",
    "        input = F.relu(self.bn_2(self.deconv_2(input)), inplace=True)\n",
    "        # Forward 3rd layer\n",
    "        input = F.relu(self.bn_3(self.deconv_3(input)), inplace=True)\n",
    "        # Forward 4th layer\n",
    "        input = F.relu(self.bn_4(self.deconv_4(input)), inplace=True)\n",
    "        # Final layer\n",
    "        return torch.tanh(self.deconv_5(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # 1st layer input: batch_size x 3 x 64 x 64\n",
    "        self.conv_1  = nn.Conv2d(in_channels=3, out_channels=ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # 2nd layer input: batch_size x 128 x 32 x 32 (for ndf = 128)\n",
    "        self.conv_2  = nn.Conv2d(in_channels=ndf, out_channels=2*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_2    = nn.BatchNorm2d(num_features=2*ndf)\n",
    "        # 3rd layer input: batch_size x 256 x 16 x 16 (for ndf = 128)\n",
    "        self.conv_3  = nn.Conv2d(in_channels=2*ndf, out_channels=4*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_3    = nn.BatchNorm2d(num_features=4*ndf)\n",
    "        # 4th layer input: batch_size x 512 x 8 x 8 (for ndf = 128)\n",
    "        self.conv_4  = nn.Conv2d(in_channels=4*ndf, out_channels=8*ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn_4    = nn.BatchNorm2d(num_features=8*ndf)\n",
    "        # Final layer input: batch_size x 1024 x 4 x 4 (for ndf = 128)\n",
    "        self.conv_5  = nn.Conv2d(in_channels=8*ndf, out_channels=1, kernel_size=4, bias=False)\n",
    "        # Output size: batch_size x 1 x 1 x 1\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Forward 1st layer\n",
    "        input = F.leaky_relu(self.conv_1(input), negative_slope=0.2, inplace=True)\n",
    "        # Forward 2nd layer\n",
    "        input = F.leaky_relu(self.bn_2(self.conv_2(input)), negative_slope=0.2, inplace=True)\n",
    "        # Forward 3rd layer\n",
    "        input = F.leaky_relu(self.bn_3(self.conv_3(input)), negative_slope=0.2, inplace=True)\n",
    "        # Forward 4th layer\n",
    "        input = F.leaky_relu(self.bn_4(self.conv_4(input)), negative_slope=0.2, inplace=True)\n",
    "        # Final layer\n",
    "        return torch.sigmoid(self.conv_5(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization (page 3)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_dcgan(nz, ngf, ndf, device, lr=0.0002, betas=(0.5, 0.999)):\n",
    "    # Get models\n",
    "    model_G = Generator(nz=nz, ngf=ngf).to(device)\n",
    "    model_D = Discriminator(ndf=ndf).to(device)\n",
    "    \n",
    "    # Init weights\n",
    "    [m.apply(weights_init) for m in (model_G, model_D)]\n",
    "    # Set starting epoch to 0 as default\n",
    "    epoch_start    = 0\n",
    "    # Init saved losses\n",
    "    saved_losses_G = []\n",
    "    saved_losses_D = []\n",
    "    \n",
    "    # Check for pretrained Model\n",
    "    if os.path.isfile('./saved_models/DCGAN_saved_model.tar'):\n",
    "        pretrained = \"Users_answer\"\n",
    "        while pretrained not in [\"y\",\"n\"]:\n",
    "            pretrained = input(\"Pretrained Model available, use it? [y/n]:\")\n",
    "        # If User says \"y\", load weights\n",
    "        if pretrained==\"y\":\n",
    "            # Load data\n",
    "            saved_data = torch.load('./saved_models/DCGAN_saved_model.tar', map_location=device)\n",
    "            # Transmit data\n",
    "            model_G.load_state_dict(saved_data['G_state_dict'])\n",
    "            model_D.load_state_dict(saved_data['D_state_dict'])\n",
    "            epoch_start    = saved_data['current_epoch']\n",
    "            saved_losses_G = saved_data['losses_G']\n",
    "            saved_losses_D = saved_data['losses_D']\n",
    "            \n",
    "    # Define Adam optimizer\n",
    "    opt_G = optim.Adam(model_G.parameters(), lr=lr, betas=betas)\n",
    "    opt_D = optim.Adam(model_D.parameters(), lr=lr, betas=betas)\n",
    "    \n",
    "    return model_G, model_D, opt_G, opt_D, epoch_start, (saved_losses_G, saved_losses_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dcgan(epochs, model_G, model_D, loss_func, opt_G, opt_D, train_dl, device, \n",
    "              epoch_start=0, saved_losses=([],[]), show_iter=200):\n",
    "    \n",
    "    # Check if start_epoch is greater than number of epochs, stop if the case\n",
    "    if epoch_start>epochs:\n",
    "        return\n",
    "    \n",
    "    # Extract saved losses\n",
    "    saved_losses_G, saved_losses_D = saved_losses\n",
    "    \n",
    "    # Take time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epoch_start, epochs):\n",
    "        for i, (x_real, _) in enumerate(train_dl):\n",
    "            # Get batch_size since batch_size is different for last observations\n",
    "            batch_size = x_real.size()[0]\n",
    "            \n",
    "            ### Discriminator Training ###\n",
    "            model_D.zero_grad()\n",
    "            # Real pictures\n",
    "            out_real = model_D(x_real.to(device)).view(-1)\n",
    "            lossD_real = loss_func(out_real, torch.ones(batch_size, device=device))\n",
    "            \n",
    "            # Fake pictures \n",
    "            ## Generate Noise\n",
    "            noise = torch.randn(batch_size, model_G.nz, 1, 1, device=device)\n",
    "            out_fake_D = model_D(model_G(noise).detach()).view(-1)\n",
    "            # Loss function with all zeros for being fake\n",
    "            lossD_fake = loss_func(out_fake_D, torch.zeros(batch_size, device=device))\n",
    "            lossD = lossD_real + lossD_fake\n",
    "            \n",
    "            lossD.backward()\n",
    "            opt_D.step()\n",
    "            \n",
    "            ### Generator Training ###\n",
    "            model_G.zero_grad()\n",
    "            out_fake_G = model_D(model_G(noise)).view(-1)\n",
    "            lossG = loss_func(out_fake_G, torch.ones(batch_size, device=device))\n",
    "            \n",
    "            lossG.backward()\n",
    "            opt_G.step()\n",
    "            \n",
    "            # Save lossos\n",
    "            ## Discriminator\n",
    "            saved_losses_D.append(lossD.clone().detach())\n",
    "            ## Generator\n",
    "            saved_losses_G.append(lossG.clone().detach())\n",
    "            \n",
    "            if (i+epoch*len(train_dl))%show_iter == 0:\n",
    "                # get time values\n",
    "                hours, rem = divmod(time.time()-start_time, 3600)\n",
    "                minutes, seconds = divmod(rem, 60)\n",
    "                print('({:0>2}:{:0>2}:{:0>2}) [{}/{}][{}/{}] -> {:.2f}%\\tLoss_D: {:.4f}, D(x): {:.4f}\\tLoss_G: {:.4f}, D(G(z)): {:.4f}'.format(\n",
    "                    int(hours),int(minutes), int(seconds), epoch, epochs, i, len(train_dl),\n",
    "                    100*(i+epoch*len(train_dl))/(epochs*len(train_dl)), lossD, out_real.mean(),\n",
    "                    lossG, out_fake_D.mean()))\n",
    "                \n",
    "            if (i+epoch*len(train_dl))%(5*show_iter) == 0:\n",
    "                # Plot some training images\n",
    "                fakes = model_G(torch.randn(128,100,1,1,device=device)).detach().cpu()\n",
    "                plt.figure(figsize=(12,12))\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(\"Generated Images\")\n",
    "                plt.imshow(np.transpose(vutils.make_grid(fakes[:16], padding=2, normalize=True),(1,2,0)))\n",
    "                plt.pause(0.001)\n",
    "                \n",
    "        ###############\n",
    "        # save current state, epoch and saved losses\n",
    "        torch.save({'G_state_dict': model_G.state_dict(),\n",
    "                    'D_state_dict': model_D.state_dict(),\n",
    "                    'current_epoch': epoch+1,\n",
    "                    'losses_G': saved_losses_G,\n",
    "                    'losses_D': saved_losses_D,\n",
    "                   },'./saved_models/DCGAN_saved_model.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Define Image size\n",
    "image_size = 64\n",
    "# Select dataset\n",
    "data_folder = './data/'\n",
    "\n",
    "train_ds = dset.ImageFolder(root = data_folder,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                # Transform data from [0,1] scale to [-1,1] scale\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ]))\n",
    "# Constuct dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
    "# Plot some training images\n",
    "real_examples = next(iter(train_dl))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_examples[0][:16], padding=2, normalize=True),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_func = nn.BCELoss()\n",
    "# Get initialized models and optimizers\n",
    "model_G, model_D, opt_G, opt_D, epoch_start, saved_losses = get_dcgan(nz=100,\n",
    "                                                                      ngf=64,\n",
    "                                                                      ndf=64,\n",
    "                                                                      device=device,\n",
    "                                                                      lr=0.0002,\n",
    "                                                                      betas=(0.5, 0.999))\n",
    "# Fit DCGAN\n",
    "fit_dcgan(100, model_G, model_D, loss_func, opt_G, opt_D, train_dl, device, epoch_start, saved_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Losses\n",
    "model_G, model_D, opt_G, opt_D, epoch_start, saved_losses = get_dcgan(nz=100,\n",
    "                                                                      ngf=64,\n",
    "                                                                      ndf=64,\n",
    "                                                                      device=device,\n",
    "                                                                      lr=0.0002,\n",
    "                                                                      betas=(0.5, 0.999))\n",
    "# Transfor to numpy\n",
    "np_loss_G = np.array([float(x.clone().detach()) for x in saved_losses[0]])\n",
    "np_loss_D = np.array([float(x.clone().detach()) for x in saved_losses[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, lags=10):\n",
    "    # init\n",
    "    ma_fi = np.zeros(lags)\n",
    "    ma    = np.copy(x[lags:])\n",
    "    for lag in range(lags):\n",
    "        # fade in\n",
    "        ma_fi += np.concatenate((np.zeros(lag), x[:lags-lag]))\n",
    "        # actual moving average\n",
    "        ma += x[lags-lag-1:-lag-1]\n",
    "    out = np.concatenate((ma_fi/range(1,lags+1), ma/lags))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_loss_G = moving_average(np_loss_G, len(train_dl))\n",
    "ma_loss_D = moving_average(np_loss_D, len(train_dl))\n",
    "np_losses = np.column_stack((np_loss_G, np_loss_D, ma_loss_G, ma_loss_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "## 'python -m visdom.server' into terminal\n",
    "from visdom import Visdom\n",
    "\n",
    "viz = Visdom()\n",
    "\n",
    "viz.line(\n",
    "    Y = np_losses,\n",
    "    X = np.repeat(np.arange(len(np_loss_G))/float(len(train_dl)), 4).reshape(-1,4),\n",
    "    opts = dict(xlabel='epoch',\n",
    "                ylabel='Loss',\n",
    "                title='training loss DCGAN',\n",
    "                legend=[\"Generator\",\n",
    "                        \"Discriminator\",\n",
    "                        \"Generator Moving Average\",\n",
    "                        \"Discriminator Moving Average\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "fakes = model_G(torch.randn(128,100,1,1,device=device)).detach().cpu()\n",
    "plt.figure(figsize=(13,13))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(fakes[:64], padding=2, normalize=True),(1,2,0)))\n",
    "plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
